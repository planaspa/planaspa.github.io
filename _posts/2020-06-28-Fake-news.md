---
layout: post
title: "Controlar las fake news"
author: Pablo Lanaspa
profile_pic: /assets/img/bio_img.png
post_pic: /assets/img/posts/20200628/fake_news.png
date: 2020-06-28 10:00:10 -0000
categories: []
tags: [Facebook, plataformas, redes-sociales, Twitter, fake-news]
summary: "Facebook y Twitter no están logrando controlar las fake news, tampoco parecen las más apropiadas para hacerlo... ¿Cual es la solución?"
visible_on_index: false
---

Las elecciones de EEUU están a la vuelta de la esquina y ya se está comenzando a generar mucho revuelo acerca de que políticas deberían llevar a cabo las redes sociales para evitar que las *fake news* fuercen el voto de la población en una dirección o en otra. Además, el movimiento de *boicot a Facebook* está acaparando muchas portadas esta semana, [Coca-Cola y Unilever](https://cincodias.elpais.com/cincodias/2020/06/27/companias/1593242852_284102.html){:target="_blank"} se han sumado a otras grandes marcas en la decisión de no publicitarse a través de redes sociales hasta que “no se tomen medidas para parar la desinformación y discursos de odio en sus plataformas” (Levi Strauss & Co.).

Más allá de las posiciones que estén tomando los diferentes involucrados en todo este lío, lo que está claro es que a día de de hoy existe una necesidad que el mercado está demandando y que las grandes redes sociales no están sabiendo cubrir: **Un servicio de control del contenido que funcione**. 

Por centrar el tiro, en este informe quincenal solo voy a abrir el debate acerca de como debería ser un modelo que funcione alrededor de la detección de *fake news*, no obstante, el análisis podría abrirse a la detección y actuación de otros tipos de contenido. 

{% include posts/images/image_left_nourl.html url="/assets/img/posts/20200628/fake_news.png" description="Fake news" %}

Está claro que existe un espacio aún no cubierto en el mercado que se encargue de verificar y garantizar la fiabilidad de las noticias que se publican en internet, este es un problema a escala mundial y nadie parece tener un producto apropiado, si alguien llegase con una solución medio factible estoy seguro que más de un VC estaría dispuesto a poner algún kilo encima de la mesa casi sin mirar.

Controlar el contenido de las redes sociales es quizás el talón de Aquiles de las grandes redes sociales las cuales, en parte, se benefician de la polarización de sus usuarios. 

Se benefician de la  polarización porque ésta les incita a publicar más contenido, además, que la gente entre al trapo les sirve como incentivo para que más usuarios utilicen la red social y de manera más intensiva. Por otro lado, parte de sus ingresos vienen de la pubicidad que pagan los partidos políticos que por definición tienen la intención de generar propaganda y fomentar aún más si cabe la polarización de la ciudadania para beneficio de su propio partido.

Controlar el contenido en la redes sociales es una tarea muy complicada, pero está claro que los incentivos para llevar a cabo esta tarea parecen no estar del lado de los gestores de las redes sociales puesto que van en contra de sus objetivos de negocio. Además, existe una cuestión ética que creo que merece la pena desgranar.

## Un nodo central de censura

Controlar contenido en las redes sociales no deja de ser un eufemismo de censurar la libertad de expresión de las personas, aunque lo que éstas digan sean *fake news*. Uno de los grandes éxitos de las democracias es precisamente la capacidad del ciudadano de disponer de libertad de expresión y exponer sus ideas para que sean votadas por el resto de la ciudadanía. Por esta razón, cabe exponer las siguientes preguntas: **¿Quién debe estar al cargo de controlar (en definitiva, censurar) el contenido de las redes sociales? ¿Debería incluso existir este sistema de control?**

Actualmente, son las propias redes sociales las que se encargan de censurar contenido. Es decir, un único organismo en el mundo se encarga de censurar los contenidos en cada red social. Friedrich Hayek, premio Nobel de economía, ya expuso durante toda su obra que si los sistemas organizativos de la sociedad se basan en la existencia de un nodo centralizador del poder que gestione los recursos o la información disponible a sus ciudadanos, esto lleva siempre en última instancia al totalitarismo.

Los nodos centrales de censura pueden acarrear consigo el monopolio de la generación de contenido con un sesgo único, el que permita el organismo central de censura. Lo cual nos llevaría a preguntarnos qué principios morales y éticos son los que rigen en ese organismo central de censura... ¿Cuales son los principios de cada una de las redes sociales? Una vez se comienza a censurar la libertad de expresión se hace en base a unos principios, ¿debe un ente único determinar cuales son los principios sobre los que puede regir una conversación en internet? 

Muchas personas pensarán que no debería una única empresa privada decidir qué contenidos se publican en su red social y cuales no, sin embargo, los gobiernos tampoco parecen  una vía. En muchos países donde no existe la libertad de expresión, las redes sociales son el único medio a través del cual los ciudadanos pueden expresarse libremente y ofrecer otros puntos de vista sobre las situaciones. Es por ello por lo que en muchos países donde la libertad de expresión brilla por su ausencia las redes sociales son las primeras en sufrir la censura de un nodo central de censura muy poderoso, el gobierno.

Mi objetivo no es dar aquí una respuesta a este dilema moral, pero si que me parece interesante dejar las preguntas abiertas para generar el debate. La centralización de la censura de contenido va más allá de la operativa, es una cuestión ética.

## En busca de la solución

Una vez hemos visto que parece que los perversos incentivos de negocio en los que se ven envueltas las propias redes sociales y que el debate ético/moral entorno a darles el poder único de censura tampoco les sitúa como los mejores candidatos a ejercer este poder... ¿Quién debería hacerlo? Desde mi punto de vista existen dos modelos diferentes con sus ventajas y sus desventajas.

### Modelo de Moodys

Las personas que conozcáis de cerca las agencias de calificación de riesgo como Moodys, Standard & Poor’s o Fitch os resultará familiar esta vía. A día de hoy, cuando un país o una empresa quiere realizar una emisión de deuda en el mercado, debe de acudir a estas agencias para que le pongan una nota a la capacidad de pagar la deuda que tiene para que las personas que quieran dar dinero al país o empresa interesada en emitir deuda sepan que tipo de riesgo se están tomando y para que les verifiquen el estado real de la compañía y de sus números.

¿Tendría sentido algo así en la detección de *fake news*? Por supuesto no sería algo en tiempo real porque no permitiría a estas agencias calificar cada noticia, pero quizás si que fuese escalable para calificar la cantidad desinformación o información mal intencionada que generasen ciertos sitios webs relevantes a lo largo del año y tener una nota que se fuese actualizando con el tiempo, como los bonos en el mercado. 

Si los diferentes sitios webs que publican información se viesen obligados a tener que publicar dicha nota, las redes sociales podrían acompañar las noticias compartidas con esa nota para que los usuarios viesen a golpe de vista la nota que la fuente de la noticia tiene. Este modelo es un tanto diferente al actual modelo de verificación de noticias que vemos en España, verificar noticias muy específicas no escala a dar un servicio más global.

No obstante, incluso esta no es una solución que escale para dar servicios a cada uno de los sitios webs ni a cada pieza de contenido, pero si que es una solución que podría mejorar mucho la situación actual. En definitiva, externalizar el proceso de calificación del contenido a agentes externos que no son *playes* únicos y que no sufren de los mismos incentivos perversos que la red social. 

¿Quien quiere ser el próximo Moodys de las noticias?

### Modelo descentralizado o automático

La única manera de llegar al grano fino de las noticias es a través de una red descentralizada o de un servicio automático de calificación, donde existan tantos elementos capaces de hacer seguimiento y evaluar en tiempo real como contenidos se generen.

En el caso de una red enorme de evaluadores independientes de *fake news* genera muchas dudas al respecto de que cualificación tienen dichos evaluadores para verificar una noticia y si todos lo harían bajo el mismo criterio. Más a más, dicha red debería ofrecer algún tipo de incentivo a sus calificadores que habría que pensar, evaluar el contenido es una tarea compleja y minuciosa, si queremos escala debería existir algún incentivo y alguna manera de castigar las malas prácticas.

En el caso de un software automático capaz de controlar el contenido surgen las mismas cuestiones que en la red descentralizada. El software debe ser alimentado por un montón de noticias ya calificadas y debe irse actualizando con el tiempo, por lo que surgen las mismas cuestiones sobre quién debería sentar las bases de clasificación del software y quién debería etiquetar los datos de aprendizaje del software. Mi sesgo de ingeniero informático me lleva a pensar que esta sería la vía ideal aunque nunca perfecta.


Esta oportunidad me parece enorme, apasionante y que puede generar un impacto enorme hacia donde puede avanzar el mundo.

¿Que te parece a tí?... ¿Crees que se debería controlar el contenido expuesto en las redes sociales? ¿Dónde estaría limite? ¿Quién debería hacerlo? El espacio está libre y alguien debería lanzarse a ocuparlo.